{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizhenwang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yizhenwang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yizhenwang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yizhenwang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yizhenwang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yizhenwang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from math import sqrt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from utils import test_accuracy, projection, veccos, binary_search_cx, \\\n",
    "                  find_exp_score, find_slab_score, project_l2_centroid, \\\n",
    "                  project_l2_centroid_straight, project_slab, project_slab_straight,\\\n",
    "                  contaminate_dataset\n",
    "\n",
    "from attackers import StraightAttack, SemiOnlineAttack, ConcentratedAttack, GreedyAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(dataset, taus, contamination_levels):\n",
    "    \n",
    "    filepath = \"./data/\"+dataset+\"/\"\n",
    "    clf = LogisticRegression(fit_intercept=False, solver='liblinear')\n",
    "    res = [[0 for a in taus] for b in contamination_levels]\n",
    "    clf_offline = LogisticRegression(fit_intercept=False, solver='liblinear')\n",
    "    w_res = [[] for b in contamination_levels]\n",
    "    acc_res = [[0 for a in taus] for b in contamination_levels]\n",
    "    \n",
    "    for i in range(n_exp):    \n",
    "        #print (\"Running the {}-th experiment\".format(i))\n",
    "        start_time = time.time()\n",
    "        filename = filepath+str(i)\n",
    "        with open(filename,\"rb\") as f:\n",
    "            datasets = pickle.load(f)\n",
    "\n",
    "        X_init, Y_init = datasets[0] # generate defense constraints and init w if necessary.\n",
    "        X_clean, Y_clean = datasets[1] # the clean data stream\n",
    "        X_valid, Y_valid = datasets[2] # validation set\n",
    "        X_test, Y_test = datasets[3]   # the actual test set\n",
    "\n",
    "        clf.fit(X_init, Y_init)\n",
    "        d = X_init.shape[1]\n",
    "        w_0 = np.zeros((1,d))\n",
    "        #print (\"Initial accuracy is {}\".format(test_accuracy(X_test, Y_test, w_0)))\n",
    "        w_t = -clf.coef_\n",
    "        #w_t /= norm(w_t)\n",
    "        #w_0 = -w_t\n",
    "        #print (\"Target accuracy is {}\".format(test_accuracy(X_test, Y_test, w_t)))\n",
    "        \n",
    "        clf_offline.fit(X_clean, Y_clean)\n",
    "        w_b = clf_offline.coef_\n",
    "        w_b /= norm(w_b)\n",
    "        #w_b = -w_t\n",
    "        \n",
    "        if attack_method == \"straight\":\n",
    "            attacker = StraightAttack()\n",
    "            attacker.set_param(datasets, w_0, w_t, R, eta, \n",
    "                                        defense, n_iter_warmup, n_attack) \n",
    "        elif attack_method == \"greedy\":\n",
    "            attacker = GreedyAttack()\n",
    "            attacker.set_param(datasets, w_0, w_t, R, eta, \n",
    "                                        defense, n_iter_warmup, n_attack) \n",
    "        elif attack_method == \"concentrated\":\n",
    "            attacker = ConcentratedAttack()\n",
    "            attacker.set_param(datasets, w_0, w_t, R, eta, \n",
    "                                        defense, n_iter_warmup, n_attack)         \n",
    "        elif attack_method == \"semi-online\":\n",
    "            attacker = SemiOnlineAttack()\n",
    "            X_adv, Y_adv = X_clean[:n_attack, :], Y_clean[:n_attack]\n",
    "            attacker.set_param(datasets, w_0, w_t, R, eta, \n",
    "                                        defense, n_iter_warmup, n_attack, (-X_adv, Y_adv))\n",
    "        attacker.set_init_set(X_init, Y_init)\n",
    "        if defense_method == \"slab\":\n",
    "            mu, scores = attacker.slab_scores()\n",
    "        elif defense_method == \"norm\":\n",
    "            mu, scores = attacker.l2_norms()\n",
    "        elif defense_method == \"L2\":\n",
    "            mu, scores = attacker.l2_distances_to_centroid()\n",
    "        \n",
    "        attacker.warmup(n_iter_warmup)\n",
    "        w_b = attacker.w_curr\n",
    "        \n",
    "        print (scores[-1], sum(scores)/len(scores), scores[int(len(scores)/2)])\n",
    "        return (find_regime_threshold(mu, w_b, -w_b, defense_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_regime_threshold(mu, w_0, w_t, defense_method):\n",
    "    \n",
    "    if defense_method == \"norm\":\n",
    "        return (0, 0)\n",
    "    elif defense_method == \"L2\":\n",
    "        mu1, mu0 = mu[0].flatten(), mu[1].flatten()\n",
    "        #print (np.linalg.norm(mu1), np.linalg.norm(mu0))\n",
    "        high = min(np.linalg.norm(mu1), np.linalg.norm(mu0))\n",
    "        b = (w_t-w_0).flatten()\n",
    "        if ((np.dot(mu1, b))>0) or ((np.dot(mu0, -b))>0):\n",
    "            low = 0\n",
    "        else:\n",
    "            s1 = abs(np.dot(mu1, b)/np.linalg.norm(b))\n",
    "            s2 = abs(np.dot(mu0, -b)/np.linalg.norm(-b))\n",
    "            #print (s1,s2)\n",
    "            low = min(s1, s2)\n",
    "            low = max(low, 0)\n",
    "        return (low, high)\n",
    "    elif defense_method == \"slab\":\n",
    "        mu1, mu0 = mu[0].flatten(), mu[1].flatten()\n",
    "        b = mu1 - mu0\n",
    "        if np.dot(b, (w_t-w_0).flatten())<0:\n",
    "            b = -b\n",
    "            #print (\"flipped\")\n",
    "        t1 = np.dot(-b, mu1)\n",
    "        t2 = np.dot(b, mu0)\n",
    "        #print (t1, t2)\n",
    "        low = min(t1, t2)\n",
    "        low = max(low, 0)\n",
    "        high = min(abs(t1), abs(t2))\n",
    "        return (low, high)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST\n",
      "10.939077 5.9942205369472505 5.786255\n",
      "10.630243 5.337613325327635 5.237629\n",
      "29.806637 4.787447480698066 3.603691\n",
      "fashionMNIST\n",
      "15.78008818241856 7.916402778701682 7.543576856862157\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-be92951f9aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdefense_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefense_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdefense_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"att-only\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mthres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefense_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontamination_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m#defense_range = \"all-pts\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#experiment(dataset, taus, contamination_levels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f0de7bd0fa6f>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(dataset, taus, contamination_levels)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#print (\"Target accuracy is {}\".format(test_accuracy(X_test, Y_test, w_t)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mclf_offline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mw_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_offline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mw_b\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_exp = 1\n",
    " \n",
    "#d, eta = 784, 0.01\n",
    "#n_attack, n_clean, n_init, n_test, n_valid = 100, 8000, 1000, 1000, 500\n",
    "#n_iter_warmup = n_clean\n",
    "defense_method = \"norm\"\n",
    "defense = {defense_method:0}\n",
    "dataset = \"MNIST\"\n",
    "\n",
    "R, max_tau = 10, 10\n",
    "\n",
    "taus = [item/2 for item in range(0, max_tau*2)]\n",
    "contamination_levels = [0]\n",
    "\n",
    "#attack_methods = [\"straight\", \"greedy\", \"semi-online\", \"concentrated\"]\n",
    "attack_method = \"semi-online\"\n",
    "defense_methods = [\"norm\", \"L2\", \"slab\"]\n",
    "thres = {}\n",
    "for dataset in [\"MNIST\", \"fashionMNIST\", \"IMDB\", \"BreastCancer\"]:\n",
    "    print (dataset)\n",
    "    if dataset == \"MNIST\":\n",
    "        d, eta = 784, 0.01\n",
    "        n_attack, n_clean, n_init, n_test, n_valid = 100, 8000, 1000, 1000, 500\n",
    "        n_iter_warmup = n_clean\n",
    "    elif dataset == \"fashionMNIST\":\n",
    "        d, eta = 784, 0.01\n",
    "        n_attack, n_clean, n_init, n_test, n_valid = 100, 8000, 1000, 1000, 500\n",
    "        n_iter_warmup = n_clean\n",
    "    elif dataset == \"IMDB\":\n",
    "        d, eta = 100, 0.01\n",
    "        n_attack, n_clean, n_init, n_test, n_valid = 200, 10000, 5000, 5000, 2000\n",
    "        n_iter_warmup = n_clean\n",
    "    else:\n",
    "        d, eta = 9, 0.05\n",
    "        n_attack, n_clean, n_init, n_test, n_valid = 80, 400, 100, 100, 50\n",
    "        n_iter_warmup = n_clean\n",
    "        \n",
    "    for defense_method in defense_methods:\n",
    "        defense_range = \"att-only\"\n",
    "        thres[(dataset, defense_method)] = experiment(dataset, taus, contamination_levels)\n",
    "        #defense_range = \"all-pts\"\n",
    "        #experiment(dataset, taus, contamination_levels)\n",
    "        \n",
    "print (thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_method = \"L2\"\n",
    "defense = {defense_method:0}\n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    defense_range = \"att-only\"\n",
    "    experiment(dataset, taus, contamination_levels)\n",
    "    #defense_range = \"all-pts\"\n",
    "    #experiment(dataset, taus, contamination_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_method = \"slab\"\n",
    "defense = {defense_method:0}\n",
    "\n",
    "#attack_methods = [\"straight\", \"greedy\", \"semi-online\", \"concentrated\"]\n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    defense_range = \"att-only\"\n",
    "    experiment(dataset, taus, contamination_levels)\n",
    "    #defense_range = \"all-pts\"\n",
    "    #experiment(dataset, taus, contamination_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_method = \"L2\"\n",
    "defense = {defense_method:0}\n",
    "\n",
    "contamination_levels = [0, 0.05, 0.1, 0.2]\n",
    "\n",
    "attack_methods = [\"straight\"]\n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    defense_range = \"all-pts\"\n",
    "    experiment(dataset, taus, contamination_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_method = \"slab\"\n",
    "defense = {defense_method:0}\n",
    "contamination_levels = [0, 0.05, 0.1, 0.2]\n",
    "\n",
    "attack_methods = [\"straight\"]\n",
    "\n",
    "for attack_method in attack_methods:\n",
    "    defense_range = \"all-pts\"\n",
    "    experiment(dataset, taus, contamination_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (round(1234,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
